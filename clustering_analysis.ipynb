{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0928d00d",
   "metadata": {},
   "source": [
    "# Assignment 04 – Clustering Analysis  \n",
    "## Google Mergers & Acquisitions – Clustering\n",
    "\n",
    "### Section 1: Data Preparation & Setup\n",
    "\n",
    "**Domain / Industry**  \n",
    "\n",
    "This project uses a dataset of **Google mergers and acquisitions**. Each row represents a single acquisition deal executed by Google.\n",
    "\n",
    "- **Entity being clustered:** One *acquisition* (target company and deal)  \n",
    "- **Original label (target):** `country` – the country where the acquired company is based  \n",
    "- **Why segmentation matters:**  \n",
    "  For a corporate development or M&A team, it’s not enough to know *where* deals are located. It’s critical to understand distinct **deal segments**:  \n",
    "  - Small tuck-in US deals vs. large transformative acquisitions  \n",
    "  - US vs. international expansion plays  \n",
    "  - Patterns in timing and pricing across regions  \n",
    "\n",
    "Clustering can reveal natural **deal archetypes** that go beyond simple labels like “US vs. non-US,” which can help refine sourcing, risk management, and integration playbooks.\n",
    "\n",
    "Below, I load the dataset, explore the structure, handle missing values, engineer features, and standardize the data for K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f674c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Data Preparation & Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix, classification_report,\n",
    "    silhouette_score, adjusted_rand_score, normalized_mutual_info_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.1 Load dataset\n",
    "# ---------------------------------------------------------------------\n",
    "DATA_PATH = \"data/mergers and acquisitions.csv\"  # keep this path in your repo\n",
    "TARGET_COL = \"country\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nDtypes:\")\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e10083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 1.2 Basic exploration\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"\\nTop country counts:\")\n",
    "print(df['country'].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8901c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 1.3 Feature engineering\n",
    "# We will create numeric features for clustering:\n",
    "#   - year: derived from 'date'\n",
    "#   - price_num: numeric version of 'price'\n",
    "#   - log_price: log(1 + price_num)\n",
    "#   - is_us: 1 if country == 'United States', else 0\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "df['date_parsed'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df['year'] = df['date_parsed'].dt.year\n",
    "\n",
    "def parse_price(p):\n",
    "    if pd.isna(p):\n",
    "        return np.nan\n",
    "    if isinstance(p, str):\n",
    "        p = p.strip()\n",
    "        if p in ['—', '-', '— ', '']:\n",
    "            return np.nan\n",
    "        p = p.replace('$', '').replace(',', '')\n",
    "        try:\n",
    "            return float(p)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    return p\n",
    "\n",
    "df['price_num'] = df['price'].apply(parse_price)\n",
    "\n",
    "print(df[['date', 'year', 'price', 'price_num']].head())\n",
    "print(\"\\nMissing in 'year':\", df['year'].isna().sum())\n",
    "print(\"Missing in 'price_num':\", df['price_num'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ed373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 1.4 Handle missing values for numeric features (for clustering)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "df['year'] = df['year'].fillna(df['year'].median())\n",
    "df['price_num'] = df['price_num'].fillna(df['price_num'].median())\n",
    "\n",
    "df['log_price'] = np.log1p(df['price_num'])\n",
    "df['is_us'] = (df['country'] == 'United States').astype(int)\n",
    "\n",
    "feature_cols = ['year', 'log_price', 'is_us']\n",
    "print(\"Features used for clustering:\", feature_cols)\n",
    "display(df[feature_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e1ae9",
   "metadata": {},
   "source": [
    "### Why Standardization is Necessary\n",
    "\n",
    "K-means clustering is based on **Euclidean distance**. If one feature (like deal price) is on a much larger scale than another (like year), it will dominate the distance calculation and overwhelm the other variables.\n",
    "\n",
    "To avoid this, I standardize the features so that each has approximately:\n",
    "\n",
    "- Mean ≈ 0  \n",
    "- Standard deviation ≈ 1  \n",
    "\n",
    "This puts `year`, `log_price`, and `is_us` on a comparable scale, allowing K-means to treat them fairly when forming clusters of acquisition deals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fcbc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 1.5 Standardize features for clustering\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_full = df[feature_cols].values\n",
    "X_scaled = scaler.fit_transform(X_full)\n",
    "\n",
    "X_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9cf96",
   "metadata": {},
   "source": [
    "## Section 2: Labeled Baseline Review\n",
    "\n",
    "**Original Target Variable: `country`**  \n",
    "\n",
    "- Each acquisition is labeled by the **country of the acquired company**.  \n",
    "- This matters because location drives regulatory risk, integration complexity, time zones, and local market dynamics. US vs. non-US deals often require different playbooks.\n",
    "\n",
    "**Supervised Features**  \n",
    "\n",
    "For a simple supervised baseline, I predict `country` using:\n",
    "\n",
    "- `year` – when the deal occurred (captures time trends, e.g., early vs. later waves of expansion)  \n",
    "- `log_price` – deal size on a log scale (captures magnitude without being dominated by billion-dollar outliers)\n",
    "\n",
    "This is intentionally a **minimal feature set**. It gives a reasonable baseline but clearly does not capture the full richness of deals (no industry, product, or strategic fit information).\n",
    "\n",
    "Below I fit a multinomial logistic regression as a simple labeled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Labeled Baseline Review\n",
    "\n",
    "X_supervised = df[['year', 'log_price']].values\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_supervised, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000, multi_class='multinomial')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Weighted F1:\", f1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0663c18d",
   "metadata": {},
   "source": [
    "### Reflection on the Labeled Model (~150 words)\n",
    "\n",
    "The supervised model achieves reasonably strong performance given how little information it uses. Accuracy is about **0.80** and the weighted F1 score is about **0.71**, driven largely by correctly identifying **United States** deals, which dominate the dataset. The confusion matrix and classification report show that many smaller countries are misclassified into the US or other more common locations. This makes sense: with only `year` and `log_price`, the model has no direct signal about geography.\n",
    "\n",
    "From a business standpoint, this labeled approach is limited. It tells us whether a deal is likely US or non-US, but it does **not** differentiate:\n",
    "\n",
    "- Very large “headline” acquisitions vs. smaller tuck-in deals  \n",
    "- Different strategic roles of international targets  \n",
    "- Subsegments within US deals with different risk/return profiles  \n",
    "\n",
    "These gaps motivate clustering: instead of forcing everything into a fixed set of country labels, we can let the data reveal natural **deal segments** that may cut across geography and highlight more actionable patterns for M&A strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ccca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Optimal K Selection\n",
    "\n",
    "wcss = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)  # 2 to 10\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    labels_k = kmeans.labels_\n",
    "    sil = silhouette_score(X_scaled, labels_k)\n",
    "    silhouette_scores.append(sil)\n",
    "\n",
    "# 3.1 Elbow plot\n",
    "plt.figure()\n",
    "plt.plot(list(K_range), wcss, marker='o')\n",
    "plt.xlabel(\"Number of clusters (K)\")\n",
    "plt.ylabel(\"Within-Cluster Sum of Squares (Inertia)\")\n",
    "plt.title(\"Elbow Method for Optimal K\")\n",
    "plt.show()\n",
    "\n",
    "# 3.2 Silhouette plot\n",
    "plt.figure()\n",
    "plt.plot(list(K_range), silhouette_scores, marker='o')\n",
    "plt.xlabel(\"Number of clusters (K)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Scores vs. K\")\n",
    "plt.show()\n",
    "\n",
    "list(zip(K_range, silhouette_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa302bd",
   "metadata": {},
   "source": [
    "### 3.1 Elbow Method – Interpretation\n",
    "\n",
    "The elbow method plots the within-cluster sum of squares (WCSS) against K. As K increases, WCSS falls, but the *rate* of improvement slows. The “elbow” is the point where adding extra clusters buys relatively little extra cohesion.\n",
    "\n",
    "In this dataset, the curve bends noticeably around **K ≈ 3**, after which WCSS still decreases but with diminishing returns.\n",
    "\n",
    "### 3.2 Silhouette Score – Interpretation\n",
    "\n",
    "The silhouette score measures how well each point fits into its assigned cluster compared with other clusters, with values from –1 to 1 (higher is better). For this dataset, the silhouette score peaks around **K = 3** and remains competitive for slightly larger K values, but with no big improvement.\n",
    "\n",
    "This suggests that **K = 3** provides a good balance between cluster cohesion and separation for this M&A dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f30e6",
   "metadata": {},
   "source": [
    "### 3.3 K Selection Decision (100–150 words)\n",
    "\n",
    "Both the elbow and silhouette analyses point toward **K = 3** as a strong choice. The elbow plot shows a clear bend near three clusters, where additional clusters yield smaller reductions in within-cluster variance. The silhouette plot also reaches a high point at K = 3, indicating well-separated and cohesive clusters in the standardized feature space.\n",
    "\n",
    "While slightly larger K values (e.g., 7 or 8) show decent silhouette scores, they would fragment the deal universe into many small segments that are harder to interpret and act on. For a corporate development or investment banking context, **3 segments** is a practical number: large enough to capture meaningful differences in deal profile, but small enough that a deal team can remember and operationalize them.\n",
    "\n",
    "Therefore, I choose **K = 3** as the final number of clusters for the K-means model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4772b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: K-Means Clustering\n",
    "\n",
    "FINAL_K = 3\n",
    "\n",
    "kmeans_final = KMeans(n_clusters=FINAL_K, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "print(df['cluster'].value_counts())\n",
    "print(df['cluster'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a9642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Cluster Characterization\n",
    "\n",
    "cluster_sizes = df['cluster'].value_counts().sort_index()\n",
    "cluster_percentages = df['cluster'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "cluster_summary = pd.DataFrame({\n",
    "    'count': cluster_sizes,\n",
    "    'percentage': cluster_percentages.round(2)\n",
    "})\n",
    "\n",
    "feature_summary = df.groupby('cluster')[feature_cols].agg(['mean', 'median'])\n",
    "\n",
    "display(cluster_summary)\n",
    "display(feature_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f4b23",
   "metadata": {},
   "source": [
    "### 4.2 Cluster Characterization\n",
    "\n",
    "From the summary:\n",
    "\n",
    "- **Cluster 0:** Smallest group. Very high `log_price` and a high share of US deals. These are **mega-size, mostly US deals**, the big headline acquisitions.  \n",
    "- **Cluster 1:** Medium-size group. `is_us` is 0 for all rows, with moderate deal size. This cluster is **non-US expansion deals**, spread across many countries.  \n",
    "- **Cluster 2:** Largest group. Nearly all `is_us = 1` with mid-sized prices. These are **core US tuck-in acquisitions**, relatively standardized in size and geography.\n",
    "\n",
    "Distinguishing factors:\n",
    "\n",
    "- `log_price` clearly separates **Cluster 0** (billion-dollar scale) from the other two.  \n",
    "- `is_us` perfectly separates **Cluster 1** (international) from **Cluster 2** (domestic US).  \n",
    "- `year` is similar across clusters but **Cluster 0** trends slightly later on average, consistent with later-stage mega deals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Representative Examples\n",
    "\n",
    "cols_to_show = ['date', 'acquried_company', 'acquring_company',\n",
    "                'business', 'country', 'price', 'year', 'price_num', 'cluster']\n",
    "\n",
    "for c in sorted(df['cluster'].unique()):\n",
    "    print(f\"\\nCluster {c} – Representative Deals\")\n",
    "    reps = df[df['cluster'] == c].head(3)\n",
    "    display(reps[cols_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c8b70b",
   "metadata": {},
   "source": [
    "### 4.3 Representative Examples\n",
    "\n",
    "- **Cluster 0 (Mega US strategic bets):** Representative rows show very large price tags (hundreds of millions to billions), often US-based targets with high-profile products.  \n",
    "- **Cluster 1 (International expansion plays):** Examples include acquisitions in Europe, Canada, and other non-US markets at moderate deal sizes.  \n",
    "- **Cluster 2 (Core US tuck-ins):** Rows show mid-sized US companies acquired to strengthen existing Google products or teams.\n",
    "\n",
    "These representative deals make the statistical clusters more concrete and relatable to a corporate development or banking audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c716574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: PCA Visualization\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total variance captured:\", pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbca83f",
   "metadata": {},
   "source": [
    "### 5.1 What PCA Does and Why It’s Useful\n",
    "\n",
    "Principal Component Analysis (PCA) compresses the original features into a smaller number of new, uncorrelated components that capture most of the variance in the data. Here, PCA reduces the three standardized features (`year`, `log_price`, and `is_us`) into two principal components.\n",
    "\n",
    "This is useful because it lets us **visualize** the clusters in 2D while still preserving most of the structure in the M&A dataset. If clusters remain separated in PCA space, it suggests that the underlying segmentation is strong and not an artifact of only a few dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 2D Visualization of Clusters\n",
    "\n",
    "plt.figure()\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], alpha=0.7)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA (2D) – K-Means Clusters of Google M&A Deals\")\n",
    "plt.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf349b3f",
   "metadata": {},
   "source": [
    "### 5.3 PCA Interpretation (100–150 words)\n",
    "\n",
    "The PCA plot shows three clearly differentiated regions in the first two principal components, which capture most of the variance in the standardized features. One region corresponds to **Cluster 0**, which sits far in the direction associated with high `log_price`, highlighting its role as a small group of mega-deals. Two other regions represent **US mid-sized deals** and **non-US deals**, separated primarily by the `is_us` dimension.\n",
    "\n",
    "There is some overlap at the boundaries, which is expected given that deal size and timing are continuous. Still, the visualization confirms that the 3-cluster solution aligns with intuitive axes: deal size and geography, with smaller variation along the time dimension. The 2D representation captures the main structure of the clusters reasonably well and supports the idea that these segments are meaningful in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6: Compare Clusters to Original Labels\n",
    "\n",
    "crosstab = pd.crosstab(df['cluster'], df[TARGET_COL])\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f17891",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(crosstab, aspect='auto')\n",
    "plt.colorbar(label='Count')\n",
    "plt.xticks(range(len(crosstab.columns)), crosstab.columns, rotation=90)\n",
    "plt.yticks(range(len(crosstab.index)), crosstab.index)\n",
    "plt.xlabel(TARGET_COL)\n",
    "plt.ylabel(\"Cluster\")\n",
    "plt.title(\"Cluster vs. Country (Original Label)\")\n",
    "for (i, j), val in np.ndenumerate(crosstab.values):\n",
    "    plt.text(j, i, int(val), ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cddde9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment metrics\n",
    "\n",
    "ari = adjusted_rand_score(df[TARGET_COL], df['cluster'])\n",
    "nmi = normalized_mutual_info_score(df[TARGET_COL], df['cluster'])\n",
    "\n",
    "print(\"Adjusted Rand Index (ARI):\", ari)\n",
    "print(\"Normalized Mutual Information (NMI):\", nmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc37523",
   "metadata": {},
   "source": [
    "### 6.2 Interpretation (200–250 words)\n",
    "\n",
    "The crosstab shows a strong link between clusters and the original `country` label. **Cluster 2** is almost entirely composed of **United States** deals, while **Cluster 1** is purely non-US (plus a small number of “—” entries), capturing Google’s international expansion. **Cluster 0** is mostly US but includes a few non-US deals, representing the rare, very large acquisitions regardless of location.\n",
    "\n",
    "The alignment metrics (Adjusted Rand Index and Normalized Mutual Information) indicate substantial agreement between clusters and countries, but not perfect overlap. That gap is important. The clustering reveals an additional dimension – **deal size** – that cuts across geography. Mega-deals (Cluster 0) are mostly US but not exclusively, and they behave differently enough in price to justify their own segment.\n",
    "\n",
    "From a business perspective, this suggests changing how deals are categorized. Instead of viewing everything as simply “US vs. international,” a more useful view is:  \n",
    "1) US core tuck-ins,  \n",
    "2) international expansion, and  \n",
    "3) mega strategic bets.  \n",
    "\n",
    "Each of these has different risk/return trade-offs, integration requirements, and coverage expectations for bankers or corp dev teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b565c67",
   "metadata": {},
   "source": [
    "## Section 7: Segment Personas & Action Plans\n",
    "\n",
    "### Cluster 0 – “Mega US Strategic Bets” (Persona ~200–250 words)\n",
    "\n",
    "This segment represents Google’s **rare, mega-size acquisitions**, typically with billion-dollar-level price tags and a strong bias toward US targets. A typical deal in this cluster is a company that materially shifts Google’s product roadmap, competitive position, or platform footprint. These are high-visibility, board-level decisions with heavy involvement from senior leadership, extensive regulatory scrutiny, and complex integration challenges.\n",
    "\n",
    "Deals in this cluster often deliver access to massive user bases, core technology platforms, or entirely new business lines. The financial stakes are high, so diligence is deep, modeling is detailed, and downside risks must be carefully managed. Integration timelines are long, touching brand, product, engineering, and culture. From an investment banking or corporate development standpoint, these are the “once-every-few-years” transactions that define strategic narratives and investor expectations, rather than incremental improvements.\n",
    "\n",
    "### Cluster 1 – “International Expansion Plays” (Persona ~200–250 words)\n",
    "\n",
    "Cluster 1 covers **non-US acquisitions** at moderate deal sizes. A typical deal is a target in Europe, Canada, Israel, or other markets, often purchased to extend Google’s footprint into local ecosystems, acquire specialized teams, or secure technology tailored to regional needs. These deals are big enough to matter but not so large that they become company-defining transactions.\n",
    "\n",
    "Key characteristics include geographic diversity, moderate prices, and an emphasis on local market knowledge, regulatory familiarity, or specialized capabilities (e.g., mapping data, payments, infrastructure, or AI talent in specific hubs). Integration risk often revolves around cross-border legal issues, data regulations, and bridging cultural differences. For a deal team, this segment represents a steady stream of international opportunities requiring strong local advisors and repeatable playbooks.\n",
    "\n",
    "### Cluster 2 – “Core US Tuck-In Acquisitions” (Persona ~200–250 words)\n",
    "\n",
    "Cluster 2 is the **workhorse segment**: mid-sized, US-based acquisitions that support existing Google products, platforms, or capabilities. A typical deal here is an engineering-heavy company or niche product that slots into an existing business unit such as Google Cloud, Maps, or Ads. Deal sizes are meaningful but far below the mega-deal level, making these transactions more common and operationally manageable.\n",
    "\n",
    "These tuck-ins expand feature sets, accelerate roadmaps, and bring in specialized talent. Integration is usually simpler than in mega deals, focused on aligning technology stacks, migrating users, and integrating teams into Google’s culture and processes. From a banking or corp dev lens, this segment is where most of the **volume** lives: repeatable, pattern-driven deals that rely on efficient sourcing, standardized diligence, and fast execution to maintain Google’s competitive edge in key verticals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b92420c",
   "metadata": {},
   "source": [
    "### 7.2 Action Plans (≈150 words per cluster)\n",
    "\n",
    "**Cluster 0 – “Mega US Strategic Bets” – Action Plan (~150 words)**  \n",
    "For this segment, the organization should apply its **most rigorous strategic and financial discipline**. Actions include: building robust scenario models, conducting extensive regulatory and antitrust analysis, and ensuring board-level alignment before making offers. Integration plans should be developed in parallel with the deal, including leadership assignments, brand strategy, and communication plans for employees and investors. From a coverage standpoint, bankers or corp dev teams should maintain a short, carefully curated list of potential mega targets and periodically revisit them as markets evolve.\n",
    "\n",
    "**Cluster 1 – “International Expansion Plays” – Action Plan (~150 words)**  \n",
    "For international deals, the focus should be on **local expertise and repeatable cross-border processes**. Google should cultivate relationships with local advisors and regulators, develop regional integration playbooks, and standardize how it evaluates political, currency, and regulatory risk. Post-close, success depends on retaining key talent and respecting local market nuances while still integrating into the global platform. Prioritization should emphasize markets where Google’s strategic goals—such as cloud expansion, payments, or AI—overlap with strong local ecosystems.\n",
    "\n",
    "**Cluster 2 – “Core US Tuck-Ins” – Action Plan (~150 words)**  \n",
    "For US tuck-in acquisitions, speed and efficiency are crucial. Google should maintain ongoing **pipeline sourcing** from VCs, founders, and internal product teams who identify gaps that could be filled via acquisition. Standardized diligence templates, integration checklists, and playbooks should be in place so these deals can move quickly from term sheet to integration. Success metrics can focus on time-to-integration, feature adoption, and retention of critical talent. This segment is ideal for a more systematized, high-throughput M&A engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc24c06",
   "metadata": {},
   "source": [
    "## Section 8: Reflection (200–300 words)\n",
    "\n",
    "The most surprising aspect of the clustering is how cleanly the deals separate into three intuitive segments using only **year, price, and US vs. non-US status**. Without any detailed product or financial metrics, the algorithm still isolates mega-deals, international expansion plays, and core US tuck-ins. This aligns closely with how practitioners informally talk about “big bets” versus “tuck-ins,” but the clustering gives that intuition a clear, data-driven structure.\n",
    "\n",
    "The clusters partially overlap with my prior expectations for the tech M&A space, especially the dominance of US deals and the presence of a distinct set of non-US acquisitions. The added value is the explicit, quantitative recognition of mega-deals as their own segment, which cuts across geography and deserves different governance and integration approaches.\n",
    "\n",
    "From a business standpoint, this segmentation supports better **resource allocation**, more tailored **integration playbooks**, and clearer communication between corporate development, leadership, and external advisors. Limitations include the small dataset, heavy missingness in price, and the fact that important drivers (like revenue, profitability, or strategic fit) are not directly observed. Clustering is also sensitive to feature choices and the selected K.\n",
    "\n",
    "In my future work—especially in investment banking or M&A advisory—I could use clustering to segment potential targets, client portfolios, or historical transactions, helping to prioritize outreach, refine valuation comps, and build more nuanced narratives around deal pipelines."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
